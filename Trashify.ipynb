{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORgUVHuaMyYlAt6HIzEKbM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/banno-0720/Deep-Learning-Projects/blob/main/Trashify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeLVmtH1H1ra"
      },
      "source": [
        "# 1. Overview\n",
        "\n",
        "Trashify = using ML to incentivize people to pick up trash in their local area\n",
        "\n",
        "We'll start with a collection of images with bounding box files as our dataset, fine-tune an existing computer vision model to detect items in an image and then share our model as a demo others can use.\n",
        "\n",
        "TK image - update cover image for object detection\n",
        "<!-- <figure style=\"text-align: center;\">\n",
        "    <!-- figtemplate -->\n",
        "    <img src=\"https://huggingface.co/datasets/mrdbourke/learn-hf-images/resolve/main/learn-hf-text-classification/00-project-food-not-food-overview.png\"\n",
        "     alt=\"Project overview image for 'Food Not Food' classification at Nutrify, a food app. The project involves building and deploying a binary text classification model to identify food-related text using Hugging Face Datasets, Transformers, and deploying with Hugging Face Hub/Spaces and Gradio. Examples include labels for 'A photo of sushi rolls on a white plate' (food), 'A serving of chicken curry in a blue bowl' (food), and 'A yellow tractor driving over a grassy hill' (not food). The process is visually depicted from data collection to model training and demo deployment.\"\n",
        "     style=\"width: 100%; max-width: 900px; height: auto;\"/>\n",
        "     <figcaption>We're going to put on our internship hats and build a food not food text classification model using tools from the Hugging Face ecosystem.</figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRUB8bFdH1rb"
      },
      "source": [
        "## 1.1 What we're going to build\n",
        "\n",
        "We're going to be bulding Trashify ðŸš®, an **object detection model** which incentivises people to pick up trash in their local area by detecting `bin`, `trash`, `hand`.\n",
        "\n",
        "If all three items are detected, a person gets +1 point!\n",
        "\n",
        "For example, say you were going for a walk around your neighbourhood and took a photo of yourself picking up a piece (with your **hand** or **trash arm**) of **trash** and putting it in the **bin**, you would get a point.\n",
        "\n",
        "With this object detection model, you could deploy it to an application which would automatically detect the target classes and then save the result to an online leaderboard.\n",
        "\n",
        "The incentive would be to score the most points, in turn, picking up the most piecces of trash, in a given area.\n",
        "\n",
        "More specifically, we're going to follow the following steps:\n",
        "\n",
        "1. **[Data](https://huggingface.co/datasets/mrdbourke/trashify_manual_labelled_images): Problem defintion and dataset preparation** - Getting a dataset/setting up the problem space.\n",
        "2. **[Model](https://huggingface.co/docs/transformers/en/model_doc/conditional_detr): Finding, training and evaluating a model** - Finding an object detection model suitable for our problem on Hugging Face and customizing it to our own dataset.\n",
        "3. **[Demo](https://huggingface.co/spaces/mrdbourke/trashify_demo_v3): Creating a demo and put our model into the real world** - Sharing our trained model in a way others can access and use.\n",
        "\n",
        "By the end of this project, you'll have a trained model and [demo on Hugging Face](https://huggingface.co/spaces/mrdbourke/trashify_demo_v3) you can share with others:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFJSfcj6H1rd",
        "outputId": "6ce987da-5b76-44d5-b58e-7e75407593c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<iframe\n",
              "\tsrc=\"https://mrdbourke-trashify-demo-v3.hf.space\"\n",
              "\tframeborder=\"0\"\n",
              "\twidth=\"850\"\n",
              "\theight=\"850\"\n",
              "></iframe>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "\n",
        "HTML(\"\"\"\n",
        "<iframe\n",
        "\tsrc=\"https://mrdbourke-trashify-demo-v3.hf.space\"\n",
        "\tframeborder=\"0\"\n",
        "\twidth=\"850\"\n",
        "\theight=\"850\"\n",
        "></iframe>\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQRCCeZUH1rh"
      },
      "source": [
        "## 1.2 What is object detection?\n",
        "\n",
        "Object detection is the process of identifying and locating an item in an image.\n",
        "\n",
        "Where *item* can mean almost anything.\n",
        "\n",
        "For example:\n",
        "\n",
        "* Detecting car **licence plates** in a video feed (videos are a series of images) for a parking lot entrance.\n",
        "* Detecting **delivery people** walking towards your front door on a security camera.\n",
        "* Detecting **defects** on a manufacturing line.\n",
        "* Detecting [**pot holes** in the road](https://ieeexplore.ieee.org/abstract/document/9968423) so repair works can automatically be scheduled.\n",
        "* Detecting **small pests (Varroa Mite)** on the bodies of bees.\n",
        "* Detecting [**weeds** in a field](https://ai.meta.com/blog/pytorch-drives-next-gen-intelligent-farming-machines/) so you know what to remove and what to keep.\n",
        "\n",
        "--\n",
        "\n",
        "Examples of actual trash identification projects, see:\n",
        "\n",
        "- Google using machine learning for trash identification â€” [https://sustainability.google/operating-sustainably/stories/circular-economy-marketplace/](https://sustainability.google/operating-sustainably/stories/circular-economy-marketplace/)\n",
        "- Trashify website for identifying trash â€” [https://www.trashify.tech/](https://www.trashify.tech/)\n",
        "- Waste management with deep learning â€” [https://www.sciencedirect.com/science/article/abs/pii/S0956053X23001915](https://www.sciencedirect.com/science/article/abs/pii/S0956053X23001915)\n",
        "- Label Studio being used for labelling a trash dataset â€” [https://labelstud.io/blog/ameru-labeling-for-a-greener-world/](https://labelstud.io/blog/ameru-labeling-for-a-greener-world/)\n",
        "\n",
        "**Image classification** deals with classifying an image as a whole into a single `class`, object detection endeavours to find the specific target item and *where* it is in an image.\n",
        "\n",
        "One of the most common ways of showing where an item is in an image is by displaying a **bounding box** (a rectangle-like box around the target item).\n",
        "\n",
        "An object detection model will often take an input image tensor in the shape `[3, 640, 640]` (`[colour_channels, height, width]`) and output a tensor in the form `[class_name, x_min, y_min, x_max, y_max]` or `[class_name, x1, y1, x2, y2]` (this is two ways to write the same example format, there are more formats, we'll see these below in @tbl-bbox-formats).\n",
        "\n",
        "Where:\n",
        "\n",
        "* `class_name` = The classification of the target item (e.g. `\"car\"`, `\"person\"`, `\"banana\"`, `\"piece_of_trash\"`, this could be almost anything).\n",
        "* `x_min` = The `x` value of the top left corner of the box.\n",
        "* `y_min` = The `y` value of the top left corner of the box.\n",
        "* `x_max` = The `x` value of the bottom right corner of the box.\n",
        "* `y_max` = The `y` value of the bottom right corner of the box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnpWJg51H1rj"
      },
      "source": [
        "## 1.3 Why train your own object detection models?\n",
        "\n",
        "You can customize **pre-trained models** for object detection as well as API-powered models and LLMs such as [Gemini](https://ai.google.dev/gemini-api/docs/vision?lang=python#bbox), [LandingAI](https://landing.ai/agentic-object-detection) and [DINO-X](https://github.com/IDEA-Research/DINO-X-API).\n",
        "\n",
        "Depending on your requirements, there are several pros and cons for using your own model versus using an API.\n",
        "\n",
        "Training/fine-tuning your own model:\n",
        "\n",
        "| Pros | Cons |\n",
        "| :----- | :----- |\n",
        "| **Control:** Full control over model lifecycle. | Can be complex to get setup. |\n",
        "| No usage limits (aside from compute constraints). | Requires dedicated compute resources for training/inference. |\n",
        "| Can train once and deploy everywhere/whenever you want (for example, Tesla deploying a model to all self-driving cars). | Requires maintenance over time to ensure performance remains up to par. |\n",
        "| **Privacy:** Data can be kept in-house/app and doesnâ€™t need to go to a third party. | Can require longer development cycles compared to using existing APIs. |\n",
        "| **Speed:** Customizing a small model for a specific use case often means it runs much faster on local hardware, for example, modern object detection models can achieve 70-100+ FPS (frames per second) on modern GPU hardware. | |\n",
        "\n",
        "Using a pre-built model API:\n",
        "\n",
        "| Pros | Cons |\n",
        "| :----- | :----- |\n",
        "| **Ease of use:** often can be setup within a few lines of code. | If the model API goes down, your service goes down. |\n",
        "| No maintenance of compute resources. | Data is required to be sent to a third-party for processing. |\n",
        "| Access to the most advanced models. | The API may have usage limits per day/time period. |\n",
        "| Can scale if usage increases. | Can be much slower than using dedicated models due to requiring an API call. |\n",
        "\n",
        "For this project, we're going to focus on fine-tuning our own model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvY61ujjH1rk"
      },
      "source": [
        "## 1.4 Workflow we're going to follow\n",
        "\n",
        "Start with data (or skip this step and go straight to a model) -> get/customize a model -> build and share a demo.\n",
        "\n",
        "With this in mind, our motto is *data, model, demo!*\n",
        "\n",
        "More specifically, we're going to follow the rough workflow of:\n",
        "\n",
        "1. Create, preprocess and load data using [Hugging Face Datasets](https://huggingface.co/docs/datasets/index).\n",
        "2. Define the model we'd like use with [`transformers.AutoModelForObjectDetection`](https://huggingface.co/docs/transformers/en/model_doc/auto#transformers.AutoModelForObjectDetection) (or another similar model class).\n",
        "3. Define training arguments (these are hyperparameters for our model) with [`transformers.TrainingArguments`](https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments).\n",
        "4. Pass `TrainingArguments` from 3 and target datasets to an instance of [`transformers.Trainer`](https://huggingface.co/docs/transformers/en/main_classes/trainer).\n",
        "5. Train the model by calling [`Trainer.train()`](https://huggingface.co/docs/transformers/v4.40.2/en/main_classes/trainer#transformers.Trainer.train).\n",
        "6. Save the model (to our local machine or to the Hugging Face Hub).\n",
        "7. Evaluate the trained model by making and inspecting predctions on the test data.\n",
        "8. Turn the model into a shareable demo.\n",
        "\n",
        "I say rough because machine learning projects are often non-linear in nature.\n",
        "\n",
        "As in, because machine learning projects involve many experiments, they can kind of be all over the place.\n",
        "\n",
        "But this worfklow will give us some good guidelines to follow.\n",
        "\n",
        "<figure style=\"text-align: center; display: inline-block;\">\n",
        "    <!-- figtemplate -->\n",
        "    <img src=\"https://huggingface.co/datasets/mrdbourke/learn-hf-images/resolve/main/learn-hf-text-classification/01-hugging-face-workflow.png\"\n",
        "     alt=\"The diagram shows the Hugging Face model development workflow, which includes the following steps: start with an idea or problem, get data ready (turn into tensors/create data splits), pick a pretrained model (to suit your problem), train/fine-tune the model on your custom data, evaluate the model, improve through experimentation, save and upload the fine-tuned model to the Hugging Face Hub, and turn your model into a shareable demo. Tools used in this workflow are Datasets/Tokenizers, Transformers/PEFT/Accelerate/timm, Hub/Spaces/Gradio, and Evaluate.\"\n",
        "     style=\"width: 100%; max-width: 900px; height: auto;\"/>\n",
        "     <figcaption style=\"width: 100%; box-sizing: border-box;\">A general Hugging Face workflow from idea to shared model and demo using tools from the Hugging Face ecosystem. You'll notice some of the steps don't match with our workflow outline above. This is because the text-based workflow outline above breaks some of the steps down for educational purposes. These kind of workflows are not set in stone and are more of guide than specific directions. See information on each of the tools in the <a href=\"https://huggingface.co\">Hugging Face documentation</a>.</figcaption>\n",
        "</figure>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF5TShgEvyNo"
      },
      "source": [
        "# 2. Importing necessary libraries\n",
        "\n",
        "If you're running on your local computer, be sure to check out the getting [setup guide](https://www.learnhuggingface.com/extras/setup) to make sure you have everything you need.\n",
        "\n",
        "If you're using Google Colab, many of them the following libraries will be installed by default.\n",
        "\n",
        "However, we'll have to install a few extras to get everything working.\n",
        "\n",
        "We'll need to install the following libraries from the Hugging Face ecosystem:\n",
        "\n",
        "* [`transformers`](https://huggingface.co/docs/transformers/en/installation) - comes pre-installed on Google Colab but if you're running on your local machine, you can install it via `pip install transformers`.\n",
        "* [`datasets`](https://huggingface.co/docs/datasets/installation) - a library for accessing and manipulating datasets on and off the Hugging Face Hub, you can install it via `pip install datasets`.\n",
        "* [`evaluate`](https://huggingface.co/docs/evaluate/installation) - a library for evaluating machine learning model performance with various metrics, you can install it via `pip install evaluate`.\n",
        "* [`accelerate`](https://huggingface.co/docs/accelerate/basic_tutorials/install) - a library for training machine learning models faster, you can install it via `pip install accelerate`.\n",
        "* [`gradio`](https://www.gradio.app/guides/quickstart#installation) - a library for creating interactive demos of machine learning models, you can install it via `pip install gradio`.\n",
        "\n",
        "And the following library is not part of the Hugging Face ecosystem but it is helpful for evaluating our models:\n",
        "\n",
        "* [`torchmetrics`](https://lightning.ai/docs/torchmetrics/stable/) - a library containing many evaluation metrics compatible with PyTorch/Transformers, you can install it via `pip install torchmetrics`.\n",
        "\n",
        "We can also check the versions of our software with `package_name.__version__`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kRX3YggvyNq",
        "outputId": "4e66bf95-4949-4aae-fcc0-f7a296ac6b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using transformers version: 4.48.3\n",
            "Using datasets version: 3.1.0\n",
            "Using torch version: 2.6.0+cu124\n",
            "Using torchmetrics version: 1.4.1\n"
          ]
        }
      ],
      "source": [
        "# Install/import dependencies (this is mostly for Google Colab, as the other dependences are available by default in Colab)\n",
        "try:\n",
        "  import datasets, evaluate, accelerate\n",
        "  import gradio as gr\n",
        "except ModuleNotFoundError:\n",
        "  !pip install -U datasets evaluate accelerate gradio # -U stands for \"upgrade\" so we'll get the latest version by default\n",
        "  import datasets, evaluate, accelerate\n",
        "  import gradio as gr\n",
        "\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "\n",
        "# Required for evaluation\n",
        "# Can install with !pip install torchmetrics[detection]\n",
        "import torchmetrics\n",
        "import pycocotools\n",
        "\n",
        "# Check versions (as long as you've got the following versions or higher, you should be good)\n",
        "print(f\"Using transformers version: {transformers.__version__}\")\n",
        "print(f\"Using datasets version: {datasets.__version__}\")\n",
        "print(f\"Using torch version: {torch.__version__}\")\n",
        "print(f\"Using torchmetrics version: {torchmetrics.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "07ZTllwsrMbO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}